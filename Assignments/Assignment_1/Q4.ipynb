{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"Q4.csv\")\n",
    "\n",
    "total_instances = len(data)\n",
    "survived_instances = data[data[\"Survived\"] == 1]\n",
    "not_survived_instances = data[data[\"Survived\"] == 0]\n",
    "p_survived = len(survived_instances) / total_instances\n",
    "p_not_survived = len(not_survived_instances) / total_instances\n",
    "\n",
    "original_gini_impurity = 1 - (p_survived**2 + p_not_survived**2)\n",
    "print(\"Original Gini Impurity:\", original_gini_impurity)\n",
    "\n",
    "male_instances = data[data[\"Gender\"] == 1]\n",
    "female_instances = data[data[\"Gender\"] == 0]\n",
    "\n",
    "total_male = len(male_instances)\n",
    "survived_male = male_instances[male_instances[\"Survived\"] == 1]\n",
    "not_survived_male = male_instances[male_instances[\"Survived\"] == 0]\n",
    "p_survived_male = len(survived_male) / total_male\n",
    "p_not_survived_male = len(not_survived_male) / total_male\n",
    "gini_male = 1 - (p_survived_male**2 + p_not_survived_male**2)\n",
    "\n",
    "total_female = len(female_instances)\n",
    "survived_female = female_instances[female_instances[\"Survived\"] == 1]\n",
    "not_survived_female = female_instances[female_instances[\"Survived\"] == 0]\n",
    "p_survived_female = len(survived_female) / total_female\n",
    "p_not_survived_female = len(not_survived_female) / total_female\n",
    "gini_female = 1 - (p_survived_female**2 + p_not_survived_female**2)\n",
    "\n",
    "weighted_gini_impurity = (total_male / total_instances) * gini_male + (\n",
    "    total_female / total_instances\n",
    ") * gini_female\n",
    "print(\"Weighted Gini Impurity after split on gender:\", weighted_gini_impurity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impurity become more important when the decision tree is deciding on a split\n",
    "between a numerical variable compared to a categorical variable due to the\n",
    "nature of how splits are evaluated. When splitting on a categorical variable\n",
    "(e.g., gender, color), the decision tree algorithm simply has to consider the\n",
    "different categories present in that variable. It calculates impurity based on\n",
    "the distribution of classes within each category. The impurity measure assesses\n",
    "how mixed or impure the classes are within each category.\n",
    "\n",
    "However, when dealing with a numerical variable (e.g., age, income), the decision tree algorithm needs to determine where to place the split points along the numerical range. This introduces a potential infinite number of split points, which makes the decision of where to split more complex. Impurity measures play a crucial role here in evaluating which split points result in the best separation of classes.\n",
    "\n",
    "In this context, impurity measures help the decision tree algorithm assess the quality of each split point by quantifying how well it separates the classes into more homogeneous groups. The split points that result in lower impurity are preferred because they lead to more accurate and effective decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_below_25 = data[data[\"Age\"] <= 25]\n",
    "age_above_25 = data[data[\"Age\"] > 25]\n",
    "\n",
    "total_below_25 = len(age_below_25)\n",
    "survived_below_25 = age_below_25[age_below_25[\"Survived\"] == 1]\n",
    "not_survived_below_25 = age_below_25[age_below_25[\"Survived\"] == 0]\n",
    "p_survived_below_25 = len(survived_below_25) / total_below_25\n",
    "p_not_survived_below_25 = len(not_survived_below_25) / total_below_25\n",
    "gini_below_25 = 1 - (p_survived_below_25**2 + p_not_survived_below_25**2)\n",
    "\n",
    "total_above_25 = len(age_above_25)\n",
    "survived_above_25 = age_above_25[age_above_25[\"Survived\"] == 1]\n",
    "not_survived_above_25 = age_above_25[age_above_25[\"Survived\"] == 0]\n",
    "p_survived_above_25 = len(survived_above_25) / total_above_25\n",
    "p_not_survived_above_25 = len(not_survived_above_25) / total_above_25\n",
    "gini_above_25 = 1 - (p_survived_above_25**2 + p_not_survived_above_25**2)\n",
    "\n",
    "weighted_gini_impurity_age_25 = (total_below_25 / total_instances) * gini_below_25 + (\n",
    "    total_above_25 / total_instances\n",
    ") * gini_above_25\n",
    "\n",
    "print(\"Gini impurity after splitting on age <= 25:\", weighted_gini_impurity_age_25)\n",
    "\n",
    "age_below_65 = data[data[\"Age\"] < 65]\n",
    "age_above_65 = data[data[\"Age\"] >= 65]\n",
    "\n",
    "total_below_65 = len(age_below_65)\n",
    "survived_below_65 = age_below_65[age_below_65[\"Survived\"] == 1]\n",
    "not_survived_below_65 = age_below_65[age_below_65[\"Survived\"] == 0]\n",
    "p_survived_below_65 = len(survived_below_65) / total_below_65\n",
    "p_not_survived_below_65 = len(not_survived_below_65) / total_below_65\n",
    "gini_below_65 = 1 - (p_survived_below_65**2 + p_not_survived_below_65**2)\n",
    "\n",
    "total_above_65 = len(age_above_65)\n",
    "survived_above_65 = age_above_65[age_above_65[\"Survived\"] == 1]\n",
    "not_survived_above_65 = age_above_65[age_above_65[\"Survived\"] == 0]\n",
    "p_survived_above_65 = len(survived_above_65) / total_above_65\n",
    "p_not_survived_above_65 = len(not_survived_above_65) / total_above_65\n",
    "gini_above_65 = 1 - (p_survived_above_65**2 + p_not_survived_above_65**2)\n",
    "\n",
    "weighted_gini_impurity_age_65 = (total_below_65 / total_instances) * gini_below_65 + (\n",
    "    total_above_65 / total_instances\n",
    ") * gini_above_65\n",
    "\n",
    "print(\"Gini impurity after splitting on age >= 65:\", weighted_gini_impurity_age_65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split age >= 65 would lead to a better simple decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_below_25_male = male_instances[male_instances[\"Age\"] <= 25]\n",
    "age_above_25_male = male_instances[male_instances[\"Age\"] > 25]\n",
    "\n",
    "age_below_25_female = female_instances[female_instances[\"Age\"] <= 25]\n",
    "age_above_25_female = female_instances[female_instances[\"Age\"] > 25]\n",
    "\n",
    "impurity_age_below_25_male = (\n",
    "    1\n",
    "    - (\n",
    "        len(age_below_25_male[age_below_25_male[\"Survived\"] == 1])\n",
    "        / len(age_below_25_male)\n",
    "    )\n",
    "    ** 2\n",
    "    - (\n",
    "        len(age_below_25_male[age_below_25_male[\"Survived\"] == 0])\n",
    "        / len(age_below_25_male)\n",
    "    )\n",
    "    ** 2\n",
    ")\n",
    "impurity_age_above_25_male = (\n",
    "    1\n",
    "    - (\n",
    "        len(age_above_25_male[age_above_25_male[\"Survived\"] == 1])\n",
    "        / len(age_above_25_male)\n",
    "    )\n",
    "    ** 2\n",
    "    - (\n",
    "        len(age_above_25_male[age_above_25_male[\"Survived\"] == 0])\n",
    "        / len(age_above_25_male)\n",
    "    )\n",
    "    ** 2\n",
    ")\n",
    "\n",
    "impurity_age_below_25_female = (\n",
    "    1\n",
    "    - (\n",
    "        len(age_below_25_female[age_below_25_female[\"Survived\"] == 1])\n",
    "        / len(age_below_25_female)\n",
    "    )\n",
    "    ** 2\n",
    "    - (\n",
    "        len(age_below_25_female[age_below_25_female[\"Survived\"] == 0])\n",
    "        / len(age_below_25_female)\n",
    "    )\n",
    "    ** 2\n",
    ")\n",
    "impurity_age_above_25_female = (\n",
    "    1\n",
    "    - (\n",
    "        len(age_above_25_female[age_above_25_female[\"Survived\"] == 1])\n",
    "        / len(age_above_25_female)\n",
    "    )\n",
    "    ** 2\n",
    "    - (\n",
    "        len(age_above_25_female[age_above_25_female[\"Survived\"] == 0])\n",
    "        / len(age_above_25_female)\n",
    "    )\n",
    "    ** 2\n",
    ")\n",
    "\n",
    "weighted_impurity_male = (\n",
    "    len(age_below_25_male) / total_male\n",
    ") * impurity_age_below_25_male + (\n",
    "    len(age_above_25_male) / total_male\n",
    ") * impurity_age_above_25_male\n",
    "weighted_impurity_female = (\n",
    "    len(age_below_25_female) / total_female\n",
    ") * impurity_age_below_25_female + (\n",
    "    len(age_above_25_female) / total_female\n",
    ") * impurity_age_above_25_female\n",
    "\n",
    "final_impurity_gender_first = (\n",
    "    total_male / total_instances\n",
    ") * weighted_impurity_male + (total_female / total_instances) * weighted_impurity_female\n",
    "\n",
    "print(\n",
    "    \"Final model impurity (split on gender first, then on age <= 25):\",\n",
    "    final_impurity_gender_first,\n",
    ")\n",
    "\n",
    "male_below_25 = age_below_25[age_below_25[\"Gender\"] == 1]\n",
    "female_below_25 = age_below_25[age_below_25[\"Gender\"] == 0]\n",
    "\n",
    "male_above_25 = age_above_25[age_above_25[\"Gender\"] == 1]\n",
    "female_above_25 = age_above_25[age_above_25[\"Gender\"] == 0]\n",
    "\n",
    "impurity_male_below_25 = (\n",
    "    1\n",
    "    - (len(male_below_25[male_below_25[\"Survived\"] == 1]) / len(male_below_25)) ** 2\n",
    "    - (len(male_below_25[male_below_25[\"Survived\"] == 0]) / len(male_below_25)) ** 2\n",
    ")\n",
    "impurity_female_below_25 = (\n",
    "    1\n",
    "    - (len(female_below_25[female_below_25[\"Survived\"] == 1]) / len(female_below_25))\n",
    "    ** 2\n",
    "    - (len(female_below_25[female_below_25[\"Survived\"] == 0]) / len(female_below_25))\n",
    "    ** 2\n",
    ")\n",
    "\n",
    "impurity_male_above_25 = (\n",
    "    1\n",
    "    - (len(male_above_25[male_above_25[\"Survived\"] == 1]) / len(male_above_25)) ** 2\n",
    "    - (len(male_above_25[male_above_25[\"Survived\"] == 0]) / len(male_above_25)) ** 2\n",
    ")\n",
    "impurity_female_above_25 = (\n",
    "    1\n",
    "    - (len(female_above_25[female_above_25[\"Survived\"] == 1]) / len(female_above_25))\n",
    "    ** 2\n",
    "    - (len(female_above_25[female_above_25[\"Survived\"] == 0]) / len(female_above_25))\n",
    "    ** 2\n",
    ")\n",
    "\n",
    "weighted_impurity_male_age = (\n",
    "    len(male_below_25) / total_below_25\n",
    ") * impurity_male_below_25 + (\n",
    "    len(male_above_25) / total_above_25\n",
    ") * impurity_male_above_25\n",
    "weighted_impurity_female_age = (\n",
    "    len(female_below_25) / total_below_25\n",
    ") * impurity_female_below_25 + (\n",
    "    len(female_above_25) / total_above_25\n",
    ") * impurity_female_above_25\n",
    "\n",
    "final_impurity_age_first = (\n",
    "    total_below_25 / total_instances\n",
    ") * weighted_impurity_male_age + (\n",
    "    total_above_25 / total_instances\n",
    ") * weighted_impurity_female_age\n",
    "\n",
    "print(\n",
    "    \"Final model impurity (split on age <= 25 first, then on gender):\",\n",
    "    final_impurity_age_first,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(labels):\n",
    "    total_instances = len(labels)\n",
    "    unique_labels = set(labels)\n",
    "    impurity = 1.0\n",
    "\n",
    "    for label in unique_labels:\n",
    "        p_label = sum(labels == label) / total_instances\n",
    "        impurity -= p_label**2\n",
    "\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_labels = data[\"Gender\"]\n",
    "age_labels = data[\"Age\"]\n",
    "\n",
    "gender_impurity = gini_impurity(gender_labels)\n",
    "print(\"Impurity of gender:\", gender_impurity)\n",
    "\n",
    "age_below_25 = data[data[\"Age\"] <= 25]\n",
    "age_above_25 = data[data[\"Age\"] > 25]\n",
    "\n",
    "age_below_25_labels = age_below_25[\"Survived\"]\n",
    "age_above_25_labels = age_above_25[\"Survived\"]\n",
    "\n",
    "impurity_age_below_25 = gini_impurity(age_below_25_labels)\n",
    "impurity_age_above_25 = gini_impurity(age_above_25_labels)\n",
    "\n",
    "weighted_impurity_age = (\n",
    "    len(age_below_25_labels) / len(data)\n",
    ") * impurity_age_below_25 + (\n",
    "    len(age_above_25_labels) / len(data)\n",
    ") * impurity_age_above_25\n",
    "\n",
    "final_impurity_gender_first = gender_impurity + weighted_impurity_age\n",
    "print(\n",
    "    \"Final impurity (split on gender first, then on age):\", final_impurity_gender_first\n",
    ")\n",
    "\n",
    "\n",
    "age_impurity = gini_impurity(age_labels)\n",
    "print(\"Impurity of age:\", age_impurity)\n",
    "\n",
    "male_below_25 = age_below_25[age_below_25[\"Gender\"] == 1]\n",
    "female_below_25 = age_below_25[age_below_25[\"Gender\"] == 0]\n",
    "\n",
    "male_above_25 = age_above_25[age_above_25[\"Gender\"] == 1]\n",
    "female_above_25 = age_above_25[age_above_25[\"Gender\"] == 0]\n",
    "\n",
    "male_below_25_labels = male_below_25[\"Survived\"]\n",
    "female_below_25_labels = female_below_25[\"Survived\"]\n",
    "\n",
    "male_above_25_labels = male_above_25[\"Survived\"]\n",
    "female_above_25_labels = female_above_25[\"Survived\"]\n",
    "\n",
    "impurity_male_below_25 = gini_impurity(male_below_25_labels)\n",
    "impurity_female_below_25 = gini_impurity(female_below_25_labels)\n",
    "\n",
    "impurity_male_above_25 = gini_impurity(male_above_25_labels)\n",
    "impurity_female_above_25 = gini_impurity(female_above_25_labels)\n",
    "\n",
    "weighted_impurity_male = (\n",
    "    len(male_below_25_labels) / len(data)\n",
    ") * impurity_male_below_25 + (\n",
    "    len(male_above_25_labels) / len(data)\n",
    ") * impurity_male_above_25\n",
    "weighted_impurity_female = (\n",
    "    len(female_below_25_labels) / len(data)\n",
    ") * impurity_female_below_25 + (\n",
    "    len(female_above_25_labels) / len(data)\n",
    ") * impurity_female_above_25\n",
    "\n",
    "final_impurity_age_first = (\n",
    "    age_impurity + weighted_impurity_male + weighted_impurity_female\n",
    ")\n",
    "print(\"Final impurity (split on age first, then on gender):\", final_impurity_age_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender would be more useful for a split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(labels):\n",
    "    total_instances = len(labels)\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts / total_instances\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_entropy = shannon_entropy(gender_labels)\n",
    "print(\"Entropy of gender:\", gender_entropy)\n",
    "\n",
    "age_labels = data[\"Age\"]\n",
    "age_entropy = shannon_entropy(age_labels)\n",
    "print(\"Entropy of age:\", age_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When compared to the entropy of the gini index, the entroly of gender is higher\n",
    "and the entropy of age is much higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Survived\"])\n",
    "y = data[\"Survived\"]\n",
    "\n",
    "max_depth = 3\n",
    "random_state = 123123\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(\n",
    "    clf, feature_names=X.columns, class_names=[\"Not Survived\", \"Survived\"], filled=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pclass and Has_Cabin are used to split the decision at depth=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\", max_depth=max_depth, random_state=random_state\n",
    ")\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(\n",
    "    clf, feature_names=X.columns, class_names=[\"Not Survived\", \"Survived\"], filled=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of chosen features at depth=3 {Fare, Age} does not change, however their quantity\n",
    "and order laeyer does. From Age <= 2.5, Fare <= 23.25, Age <= 3.5, and Age <=\n",
    "14.0 to Fare <= 28.856, Fare <= 23.35, Age <= 9.5, and Age <= 14.0 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(\n",
    "    splitter=\"random\", max_depth=max_depth, random_state=random_state\n",
    ")\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(\n",
    "    clf, feature_names=X.columns, class_names=[\"Not Survived\", \"Survived\"], filled=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features at depth=3 do change. From Age <= 2.5, Fare <= 23.25, Age <= 3.5, and Age <=\n",
    "14.0 to Pclass <= 1.092, Embarked <= 0.214, FamilySize <= 2.123, and FamilySize <= 3.251."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = [(0.6, 0.2, 0.2), (0.7, 0.15, 0.15), (0.8, 0.1, 0.1)]\n",
    "\n",
    "criteria = [\"gini\", \"entropy\"]\n",
    "\n",
    "for criterion in criteria:\n",
    "    print(f\"Criterion: {criterion}\")\n",
    "    for train_ratio, val_ratio, test_ratio in ratios:\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            X, y, test_size=1 - train_ratio, random_state=random_state\n",
    "        )\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_temp,\n",
    "            y_temp,\n",
    "            test_size=test_ratio / (val_ratio + test_ratio),\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        clf = DecisionTreeClassifier(\n",
    "            criterion=criterion, max_depth=max_depth, random_state=random_state\n",
    "        )\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "\n",
    "        val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        print(\n",
    "            f\"Train/Val/Test Ratio: {train_ratio}/{val_ratio}/{test_ratio} - Validation Accuracy: {val_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\"\n",
    "        )\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the max depth results in the creation of more intricate decision boundaries within the feature space. This complexity enables the model to capture finer patterns present in the training data, potentially leading to higher accuracy on the training set. However, this increase in complexity also poses the risk of overfitting, as the model may start to memorize noise or outliers in the training data rather than learning generalizable patterns. Moreover, deeper trees require more computational resources and time to train due to the need to explore a larger number of possible splits. On the other hand, decreasing the max depth simplifies the decision boundaries created by the tree, making them more interpretable and reducing the risk of overfitting. While shallower trees may sacrifice some accuracy on the training data, they often generalize better to unseen data and are computationally less expensive to train. However, finding the optimal max depth involves navigating the bias-variance tradeoff, balancing model complexity with generalization performance, interpretability, and computational constraints."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
