{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "data = pd.read_csv(\"Q5.csv\")\n",
    "\n",
    "X = data.drop(columns=[\"Survived\"])\n",
    "y = data[\"Survived\"]\n",
    "random_state = 123123\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=random_state\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=random_state\n",
    ")\n",
    "\n",
    "base_models = []\n",
    "for i in range(100):\n",
    "    clf = DecisionTreeClassifier(random_state=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    base_models.append(clf)\n",
    "\n",
    "base_accuracies = []\n",
    "for clf in base_models:\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    base_accuracies.append(accuracy)\n",
    "\n",
    "ensemble_predictions = np.array([clf.predict(X_val) for clf in base_models])\n",
    "ensemble_predictions = np.mean(ensemble_predictions, axis=0) > 0.5\n",
    "\n",
    "ensemble_accuracy_val = accuracy_score(y_val, ensemble_predictions)\n",
    "\n",
    "ensemble_predictions_test = np.array([clf.predict(X_test) for clf in base_models])\n",
    "ensemble_predictions_test = np.mean(ensemble_predictions_test, axis=0) > 0.5\n",
    "ensemble_accuracy_test = accuracy_score(y_test, ensemble_predictions_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(base_accuracies, bins=20, alpha=0.7, color=\"blue\", label=\"Base Classifiers\")\n",
    "plt.axvline(\n",
    "    x=ensemble_accuracy_val,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Ensemble (Validation Set)\",\n",
    ")\n",
    "plt.axvline(\n",
    "    x=ensemble_accuracy_test, color=\"green\", linestyle=\"--\", label=\"Ensemble (Test Set)\"\n",
    ")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Accuracy Distribution of Base Classifiers and Ensemble Performance\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_values = [None, 3, 5, 7]\n",
    "min_samples_split_values = [2, 5, 10]\n",
    "min_samples_leaf_values = [1, 2, 5]\n",
    "max_features_values = [None, \"sqrt\", \"log2\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    for min_samples_split in min_samples_split_values:\n",
    "        for min_samples_leaf in min_samples_leaf_values:\n",
    "            for max_features in max_features_values:\n",
    "                base_models = []\n",
    "\n",
    "                for i in range(100):\n",
    "                    clf = DecisionTreeClassifier(\n",
    "                        max_depth=max_depth,\n",
    "                        min_samples_split=min_samples_split,\n",
    "                        min_samples_leaf=min_samples_leaf,\n",
    "                        max_features=max_features,\n",
    "                        random_state=i,\n",
    "                    )\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    base_models.append(clf)\n",
    "\n",
    "                ensemble_predictions = np.array(\n",
    "                    [clf.predict(X_val) for clf in base_models]\n",
    "                )\n",
    "                ensemble_predictions = np.mean(ensemble_predictions, axis=0) > 0.5\n",
    "\n",
    "                ensemble_accuracy_val = accuracy_score(y_val, ensemble_predictions)\n",
    "\n",
    "                ensemble_predictions_test = np.array(\n",
    "                    [clf.predict(X_test) for clf in base_models]\n",
    "                )\n",
    "                ensemble_predictions_test = (\n",
    "                    np.mean(ensemble_predictions_test, axis=0) > 0.5\n",
    "                )\n",
    "                ensemble_accuracy_test = accuracy_score(\n",
    "                    y_test, ensemble_predictions_test\n",
    "                )\n",
    "\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"max_depth\": max_depth,\n",
    "                        \"min_samples_split\": min_samples_split,\n",
    "                        \"min_samples_leaf\": min_samples_leaf,\n",
    "                        \"max_features\": max_features,\n",
    "                        \"ensemble_accuracy_val\": ensemble_accuracy_val,\n",
    "                        \"ensemble_accuracy_test\": ensemble_accuracy_test,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "for result in results:\n",
    "    print(\n",
    "        f\"Max Depth: {result['max_depth']}, \"\n",
    "        f\"Min Samples Split: {result['min_samples_split']}, \"\n",
    "        f\"Min Samples Leaf: {result['min_samples_leaf']}, \"\n",
    "        f\"Max Features: {result['max_features']}, \"\n",
    "        f\"Validation Accuracy: {result['ensemble_accuracy_val']:.4f}, \"\n",
    "        f\"Test Accuracy: {result['ensemble_accuracy_test']:.4f}\"\n",
    "    )\n",
    "\n",
    "sorted_results = sorted(\n",
    "    results, key=lambda x: x[\"ensemble_accuracy_test\"], reverse=True\n",
    ")\n",
    "\n",
    "for idx, result in enumerate(sorted_results):\n",
    "    print(\n",
    "        f\"{idx + 1}. Max Depth: {result['max_depth']}, \"\n",
    "        f\"Min Samples Split: {result['min_samples_split']}, \"\n",
    "        f\"Min Samples Leaf: {result['min_samples_leaf']}, \"\n",
    "        f\"Max Features: {result['max_features']}, \"\n",
    "        f\"Validation Accuracy: {result['ensemble_accuracy_val']:.4f}, \"\n",
    "        f\"Test Accuracy: {result['ensemble_accuracy_test']:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, there are a lot of tradeoffs to consider. For max depth, increasing the max\n",
    "depth can lead to more complex decision boundaries, potentially allowing the\n",
    "base classifiers to capture more intricate patterns in the data. However, deeper\n",
    "trees are more prone to overfitting, which may degrade ensemble performance,\n",
    "especially on unseen data. Increasing the minimum number of samples required to\n",
    "split a node can lead to simpler trees, which may generalize better to unseen\n",
    "data. However, setting this parameter too high may result in underfitting, where\n",
    "the base classifiers fail to capture important patterns in the data. Similar to\n",
    "min_samples_split, increasing the minimum number of samples required to be at a\n",
    "leaf node can lead to simpler trees and potentially better generalization.\n",
    "However, setting this parameter too high may result in overly simplistic trees\n",
    "that fail to capture sufficient information from the data. Controlling the number of features considered when looking for the best split can impact the diversity of the base classifiers in the ensemble. Setting max_features to a lower value can lead to more diverse trees, which may improve ensemble performance. However, setting it too low may result in a loss of information, leading to reduced accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results do not change id we average the predictions of the base classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a bagging ensemble classifier over a single decision tree offers several advantages, but it also comes with some drawbacks. One of the primary benefits of a bagging ensemble is improved generalization. By combining predictions from multiple base classifiers trained on different subsets of the data, bagging reduces overfitting and captures more diverse patterns in the data, leading to enhanced generalization performance. Additionally, bagging provides robustness to variance by averaging predictions, making the ensemble more stable and reliable in the face of noise or fluctuations in the data. It also reduces sensitivity to outliers, as the averaging process smooths out the impact of individual noisy data points. Furthermore, the training of multiple base classifiers in a bagging ensemble can be parallelized, resulting in faster training times, which is advantageous for large datasets or distributed computing environments.\n",
    "\n",
    "However, there are also drawbacks to using a bagging ensemble classifier.\n",
    "Firstly, the increased computational complexity and memory requirements\n",
    "associated with training multiple base classifiers can be a significant\n",
    "consideration, particularly for large ensembles or datasets. Secondly, the\n",
    "ensemble prediction of a bagging classifier is typically more complex and harder\n",
    "to interpret compared to a single decision tree, which may limit its\n",
    "applicability in scenarios where interpretability is crucial. Additionally,\n",
    "while bagging reduces overfitting on average, it is still possible for the\n",
    "ensemble to overfit the training data, especially if the base classifiers are\n",
    "highly flexible or lack diversity\n",
    "\n",
    "Regarding the potential for an ensemble model to underperform a single classifier, while theoretically possible, it is less likely in practice. Ensembles are designed to leverage the collective wisdom of multiple diverse classifiers, typically outperforming any single one. However, if the base classifiers are highly correlated or lack diversity, or if the dataset is small or poorly represented, the ensemble's performance may not exceed that of a single classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few key differences. First, regarding feature selection,Random\n",
    "Forests select a random subset of features at each split of each tree. This\n",
    "randomness helps to increase diversity among the trees and decorrelate their\n",
    "predictions. Conversely, in the simple bagging model, each base classifier is trained on the\n",
    "entire set of features. There's no explicit feature subset selection during\n",
    "training. Additionally, while Bagging can use a small number of trees, Random\n",
    "forest typically uses a very large number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=random_state\n",
    ")\n",
    "\n",
    "classifiers = {\n",
    "    \"AdaBoost (Default)\": AdaBoostClassifier(random_state=123123),\n",
    "    \"AdaBoost (Decision Tree)\": AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(), random_state=random_state\n",
    "    ),\n",
    "    \"AdaBoost (Random Forest)\": AdaBoostClassifier(\n",
    "        estimator=RandomForestClassifier(), random_state=random_state\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    results[name] = accuracy\n",
    "\n",
    "# Print results\n",
    "for name, accuracy in results.items():\n",
    "    print(f\"{name}: Validation Accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed that AdaBoost with the default base estimator tends to perform better\n",
    "than AdaBoost with Decision Trees or Random Forests as base estimators. This\n",
    "might be because the default base estimator, being a simple stump, is less prone\n",
    "to overfitting and captures the general trend in the data effectively for\n",
    "boosting purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting (GradBoost) and AdaBoost are both popular ensemble learning\n",
    "methods used to enhance the performance of weak learners by combining them into\n",
    "a strong learner. However, they employ different strategies for training\n",
    "subsequent base learners and updating instance weights. AdaBoost primarily\n",
    "minimizes the exponential loss function by iteratively adjusting the weights of\n",
    "misclassified instances, focusing on correcting the mistakes of previous weak\n",
    "learners. In contrast, Gradient Boosting optimizes an arbitrary differentiable\n",
    "loss function by sequentially fitting new base learners to the residuals (or\n",
    "gradients) of the previous ones. It directly minimizes the loss function by\n",
    "identifying the direction in the feature space where the loss decreases most\n",
    "rapidly. Another distinction lies in how they weight base learners. AdaBoost assigns equal weights to all base learners and combines their predictions using a weighted majority vote or sum. Conversely, Gradient Boosting weights base learners based on their contribution to reducing the loss function, determined by a step size (learning rate) multiplied by the contribution of the learner to the overall loss reduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=random_state\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=random_state\n",
    ")\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=random_state)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(random_state=random_state)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(random_state=random_state)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "def evaluate_model(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "gb_val_scores = evaluate_model(gb_clf, X_val, y_val)\n",
    "print(\"Validation Accuracy:\", gb_val_scores[0])\n",
    "print(\"Validation Precision:\", gb_val_scores[1])\n",
    "print(\"Validation Recall:\", gb_val_scores[2])\n",
    "print(\"Validation F1-score:\", gb_val_scores[3])\n",
    "print()\n",
    "\n",
    "print(\"AdaBoostClassifier:\")\n",
    "ada_val_scores = evaluate_model(ada_clf, X_val, y_val)\n",
    "print(\"Validation Accuracy:\", ada_val_scores[0])\n",
    "print(\"Validation Precision:\", ada_val_scores[1])\n",
    "print(\"Validation Recall:\", ada_val_scores[2])\n",
    "print(\"Validation F1-score:\", ada_val_scores[3])\n",
    "print()\n",
    "\n",
    "print(\"XGBoost (Extreme Gradient Boosting):\")\n",
    "xgb_val_scores = evaluate_model(xgb_clf, X_val, y_val)\n",
    "print(\"Validation Accuracy:\", xgb_val_scores[0])\n",
    "print(\"Validation Precision:\", xgb_val_scores[1])\n",
    "print(\"Validation Recall:\", xgb_val_scores[2])\n",
    "print(\"Validation F1-score:\", xgb_val_scores[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
