{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Embedding,\n",
    "    Bidirectional,\n",
    "    Conv1D,\n",
    "    GlobalMaxPooling1D,\n",
    "    LSTM,\n",
    "    Attention,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    Concatenate,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data\n",
    "# train_data = pd.read_csv(\"train.csv\")\n",
    "# validation_data = pd.read_csv(\"validate.csv\")\n",
    "# X_train = train_data.drop(columns=[\"genre\"]).values\n",
    "# y_train = train_data[\"genre\"]\n",
    "# X_val = validation_data.drop(columns=[\"genre\"]).values\n",
    "# y_val = validation_data[\"genre\"]\n",
    "\n",
    "# # Encode labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "# y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "# # Compute class weights\n",
    "# class_weights = compute_class_weight(\n",
    "#     class_weight=\"balanced\", classes=np.unique(y_train_encoded), y=y_train_encoded\n",
    "# )\n",
    "\n",
    "# # Tokenization\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# X_train_tokenized = tokenizer.texts_to_sequences(X_train)\n",
    "# X_val_tokenized = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "# vocab_size = len(tokenizer.word_index) + 1\n",
    "# max_seq_length = max(len(seq) for seq in X_train_tokenized)\n",
    "\n",
    "# # Padding sequences\n",
    "# X_train_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#     X_train_tokenized, maxlen=max_seq_length, padding=\"post\"\n",
    "# )\n",
    "# X_val_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#     X_val_tokenized, maxlen=max_seq_length, padding=\"post\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Positional encoding\n",
    "# def positional_encoding(seq_length, d_model):\n",
    "#     pos = np.arange(seq_length)[:, np.newaxis]\n",
    "#     i = np.arange(d_model)[np.newaxis, :]\n",
    "#     angles = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "#     pos_encoding = pos * angles\n",
    "\n",
    "#     pos_encoding[:, 0::2] = np.sin(pos_encoding[:, 0::2])\n",
    "#     pos_encoding[:, 1::2] = np.cos(pos_encoding[:, 1::2])\n",
    "#     pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "\n",
    "#     return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# # Transformer Encoder Layer\n",
    "# class TransformerEncoderLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "#         super(TransformerEncoderLayer, self).__init__()\n",
    "\n",
    "#         self.mha = tf.keras.layers.MultiHeadAttention(\n",
    "#             num_heads=num_heads, key_dim=d_model\n",
    "#         )\n",
    "#         self.ffn = tf.keras.Sequential(\n",
    "#             [\n",
    "#                 tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
    "#                 tf.keras.layers.Dense(d_model),\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "#         self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "#         self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "#         self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "#     def call(self, inputs, training):\n",
    "#         attn_output = self.mha(inputs, inputs, inputs)\n",
    "#         attn_output = self.dropout1(attn_output, training=training)\n",
    "#         out1 = self.layernorm1(inputs + attn_output)\n",
    "\n",
    "#         ffn_output = self.ffn(out1)\n",
    "#         ffn_output = self.dropout2(ffn_output, training=training)\n",
    "#         out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "#         return out2\n",
    "\n",
    "\n",
    "# # Transformer Model\n",
    "# class TransformerModel(tf.keras.Model):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         num_layers,\n",
    "#         d_model,\n",
    "#         num_heads,\n",
    "#         dff,\n",
    "#         vocab_size,\n",
    "#         num_classes,\n",
    "#         max_seq_length,\n",
    "#         rate=0.1,\n",
    "#     ):\n",
    "#         super(TransformerModel, self).__init__()\n",
    "#         self.d_model = d_model\n",
    "#         self.num_layers = num_layers\n",
    "#         self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "#         self.pos_encoding = positional_encoding(max_seq_length, d_model)\n",
    "#         self.enc_layers = [\n",
    "#             TransformerEncoderLayer(d_model, num_heads, dff, rate)\n",
    "#             for _ in range(num_layers)\n",
    "#         ]\n",
    "#         self.dropout = tf.keras.layers.Dropout(rate)\n",
    "#         self.final_layer = tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "#     def call(self, inputs, training):\n",
    "#         seq_len = tf.shape(inputs)[1]\n",
    "#         x = self.embedding(inputs)\n",
    "#         x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "#         x += self.pos_encoding[:, :seq_len, :]\n",
    "#         x = self.dropout(x, training=training)\n",
    "\n",
    "#         for i in range(self.num_layers):\n",
    "#             x = self.enc_layers[i](x, training)\n",
    "\n",
    "#         x = tf.reduce_mean(x, axis=1)  # Global average pooling\n",
    "#         return self.final_layer(x)\n",
    "\n",
    "\n",
    "# # Instantiate the Transformer model\n",
    "# num_layers = 4\n",
    "# d_model = 128\n",
    "# num_heads = 8\n",
    "# dff = 512\n",
    "\n",
    "# transformer_model = TransformerModel(\n",
    "#     num_layers,\n",
    "#     d_model,\n",
    "#     num_heads,\n",
    "#     dff,\n",
    "#     vocab_size,\n",
    "#     len(label_encoder.classes_),\n",
    "#     max_seq_length,\n",
    "# )\n",
    "\n",
    "# # Compile the model\n",
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "# transformer_model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "# # Train the model\n",
    "# history = transformer_model.fit(\n",
    "#     X_train_padded,\n",
    "#     y_train_encoded,\n",
    "#     epochs=10,\n",
    "#     validation_data=(X_val_padded, y_val_encoded),\n",
    "#     class_weight=class_weights,\n",
    "# )\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = transformer_model.evaluate(X_val_padded, y_val_encoded)\n",
    "# print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Count the occurrences of each genre\n",
    "genre_counts = train_data[\"genre\"].value_counts()\n",
    "\n",
    "\n",
    "# Plot the distribution of genres\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(genre_counts.index, genre_counts.values, color=\"skyblue\")\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Movie Genres\")\n",
    "plt.xticks(genre_counts.index, genre_counts.index.tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drama and documentary genres are the most common, with 5483 and 4861\n",
    "occurrences, respectively. Comedy is the third most common genre with 3896\n",
    "occurrences.Horror, thriller, and action genres have fewer occurrences compared\n",
    "to drama, documentary, and comedy, with 2104, 1568, and 1312 occurrences,\n",
    "respectively. The distribution of the dataset is imbalanced, with drama and\n",
    "documentary genres dominating the dataset, while horror, thriller, and action\n",
    "genres are underrepresented. This class imbalance can potentially affect the\n",
    "performance of machine learning models, particularly for genres with fewer\n",
    "occurrences, as the model may struggle to generalize well to these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "validation_data = pd.read_csv(\"validate.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=[\"genre\"])\n",
    "y_train = train_data[\"genre\"]\n",
    "X_val = validation_data.drop(columns=[\"genre\"])\n",
    "y_val = validation_data[\"genre\"]\n",
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input features\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_val_normalized = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=np.unique(y_train_encoded), y=y_train_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize text data to get vocabulary size and maximum sequence length\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(X_train_normalized)\n",
    "# vocab_size = len(tokenizer.word_index) + 1\n",
    "# max_seq_length = max([len(text.split()) for text in X_train_normalized])\n",
    "\n",
    "# # Set embedding dimension\n",
    "# embedding_dim = 100  # Example dimension, you can adjust it based on your preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hidden_layers, hidden_nodes, learning_rate):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            hidden_nodes, activation=\"relu\", input_shape=(X_train_normalized.shape[1],)\n",
    "        )\n",
    "    )\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(tf.keras.layers.Dense(hidden_nodes, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(len(label_encoder.classes_), activation=\"softmax\"))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, title):\n",
    "    plt.plot(history.history[\"loss\"], label=\"Train\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train_normalized, y_train, X_val_normalized, y_val):\n",
    "    y_train_pred_data = model.predict(X_train_normalized)\n",
    "    y_train_pred = np.argmax(y_train_pred_data, axis=1)\n",
    "    y_val_pred_data = model.predict(X_val_normalized)\n",
    "    y_val_pred = np.argmax(y_val_pred_data, axis=1)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    class_wise_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "\n",
    "    print(\"Accuracy Scores:\")\n",
    "    print(f\"Training Accuracy: {train_accuracy}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_val_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "    print(\"\\nClass-wise Accuracy:\")\n",
    "    for genre, acc in zip(label_encoder.classes_, class_wise_accuracy):\n",
    "        print(f\"{genre}: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1: Hidden Layers: 1, Hidden Nodes: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chinemerem/Documents/GitHub/ECE457B/env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Hidden Layers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Hidden Nodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_nodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(hidden_layers, hidden_nodes, learning_rate)\n\u001b[0;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_normalized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_encoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m plot_training_history(history, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Training vs Validation Error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m evaluate_model(\n\u001b[1;32m     29\u001b[0m     model, X_train_normalized, y_train_encoded, X_val_normalized, y_val_encoded\n\u001b[1;32m     30\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/ECE457B/env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/GitHub/ECE457B/env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:325\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 325\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    327\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Documents/GitHub/ECE457B/env/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/GitHub/ECE457B/env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/GitHub/ECE457B/env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/ECE457B/env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:138\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/ECE457B/env/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:390\u001b[0m, in \u001b[0;36mFunctionType.unpack_inputs\u001b[0;34m(self, bound_parameters)\u001b[0m\n\u001b[1;32m    388\u001b[0m flat \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sorted_parameters:\n\u001b[0;32m--> 390\u001b[0m   \u001b[43mflat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m      \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m dealiased_inputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    395\u001b[0m ids_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_structures = [\n",
    "    {\"hidden_layers\": 1, \"hidden_nodes\": 64},\n",
    "    # {\"hidden_layers\": 2, \"hidden_nodes\": 32},\n",
    "    # {\"hidden_layers\": 2, \"hidden_nodes\": 64},\n",
    "]\n",
    "\n",
    "for idx, structure in enumerate(model_structures, start=1):\n",
    "    hidden_layers = structure[\"hidden_layers\"]\n",
    "    hidden_nodes = structure[\"hidden_nodes\"]\n",
    "    learning_rate = 0.001\n",
    "    epochs = 100\n",
    "\n",
    "    print(\n",
    "        f\"\\nModel {idx}: Hidden Layers: {hidden_layers}, Hidden Nodes: {hidden_nodes}\"\n",
    "    )\n",
    "    model = build_model(hidden_layers, hidden_nodes, learning_rate)\n",
    "    history = model.fit(\n",
    "        X_train_normalized,\n",
    "        y_train_encoded,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val_normalized, y_val_encoded),\n",
    "        verbose=0,\n",
    "        class_weight=dict(enumerate(class_weights)),\n",
    "    )\n",
    "\n",
    "    plot_training_history(history, f\"Model {idx}: Training vs Validation Error\")\n",
    "\n",
    "    evaluate_model(\n",
    "        model, X_train_normalized, y_train_encoded, X_val_normalized, y_val_encoded\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(\n",
    "    build_model_func,\n",
    "    X_train_normalized,\n",
    "    y_train,\n",
    "    X_val_normalized,\n",
    "    y_val,\n",
    "    label_encoder,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "):\n",
    "    # Instantiate the model\n",
    "    model = build_model_func(\n",
    "        input_shape=X_train_normalized.shape[1:],\n",
    "        num_classes=len(label_encoder.classes_),\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_normalized,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val_normalized, y_val),\n",
    "        verbose=1,\n",
    "        # class_weight=dict(enumerate(class_weights)),\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    train_loss, train_accuracy = model.evaluate(X_train_normalized, y_train, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(X_val_normalized, y_val, verbose=0)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = np.argmax(model.predict(X_val_normalized), axis=-1)\n",
    "\n",
    "    # Compute class-wise accuracy\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    class_wise_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1_scores = []\n",
    "    for genre, acc in zip(label_encoder.classes_, class_wise_accuracy):\n",
    "        precision = (\n",
    "            conf_matrix[\n",
    "                label_encoder.transform([genre]), label_encoder.transform([genre])\n",
    "            ]\n",
    "            / conf_matrix[:, label_encoder.transform([genre])].sum()\n",
    "        )\n",
    "        recall = (\n",
    "            conf_matrix[\n",
    "                label_encoder.transform([genre]), label_encoder.transform([genre])\n",
    "            ]\n",
    "            / conf_matrix[label_encoder.transform([genre]), :].sum()\n",
    "        )\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        f1_scores.append(f1_score)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "    print(\"Validation Accuracy:\", val_accuracy)\n",
    "    print(\"\\nClass-wise Accuracy:\")\n",
    "    for genre, acc in zip(label_encoder.classes_, class_wise_accuracy):\n",
    "        print(f\"{genre}: {acc}\")\n",
    "    print(\"\\nF1 Scores:\")\n",
    "    for genre, f1 in zip(label_encoder.classes_, f1_scores):\n",
    "        print(f\"{genre}: {f1}\")\n",
    "\n",
    "    # Plot training history\n",
    "    plt.plot(history.history[\"loss\"], label=\"Train\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training vs Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom neural network model\n",
    "def build_custom_model(input_shape, num_classes):\n",
    "    input_layer = Input(input_shape)\n",
    "    x = Dense(128, activation=\"relu\")(input_layer)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    output_layer = tf.keras.layers.Dense((num_classes), activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_model_batch(input_shape, num_classes):\n",
    "    input_layer = Input(input_shape)\n",
    "    x = Dense(256, activation=\"relu\")(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    output_layer = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_layer)\n",
    "    x = Conv1D(128, 5, activation=\"relu\")(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    output_layer = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bidirectional_lstm(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_layer)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = Bidirectional(LSTM(32))(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    output_layer = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_with_attention(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_layer)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    attention = Attention()([x, x])\n",
    "    x = Dense(64, activation=\"relu\")(attention)\n",
    "    output_layer = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ensemble_model(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # CNN branch\n",
    "    cnn_branch = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_layer)\n",
    "    cnn_branch = Conv1D(128, 5, activation=\"relu\")(cnn_branch)\n",
    "    cnn_branch = GlobalMaxPooling1D()(cnn_branch)\n",
    "    cnn_branch = Dense(64, activation=\"relu\")(cnn_branch)\n",
    "\n",
    "    # LSTM branch\n",
    "    lstm_branch = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_layer)\n",
    "    lstm_branch = Bidirectional(LSTM(64, return_sequences=True))(lstm_branch)\n",
    "    lstm_branch = Bidirectional(LSTM(32))(lstm_branch)\n",
    "    lstm_branch = Dense(64, activation=\"relu\")(lstm_branch)\n",
    "\n",
    "    # Concatenate both branches\n",
    "    concatenated = Concatenate()([cnn_branch, lstm_branch])\n",
    "    output_layer = Dense(num_classes, activation=\"softmax\")(concatenated)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4242 - loss: 1.5679 - val_accuracy: 0.6354 - val_loss: 0.9993\n",
      "Epoch 2/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 1.0453 - val_accuracy: 0.6448 - val_loss: 0.9487\n",
      "Epoch 3/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6503 - loss: 0.9355 - val_accuracy: 0.6543 - val_loss: 0.9298\n",
      "Epoch 4/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6664 - loss: 0.8818 - val_accuracy: 0.6544 - val_loss: 0.9196\n",
      "Epoch 5/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6730 - loss: 0.8545 - val_accuracy: 0.6546 - val_loss: 0.9217\n",
      "Epoch 6/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6846 - loss: 0.8295 - val_accuracy: 0.6540 - val_loss: 0.9241\n",
      "Epoch 7/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 0.8010 - val_accuracy: 0.6564 - val_loss: 0.9300\n",
      "Epoch 8/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.7792 - val_accuracy: 0.6557 - val_loss: 0.9220\n",
      "Epoch 9/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.7631 - val_accuracy: 0.6533 - val_loss: 0.9378\n",
      "Epoch 10/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.7328 - val_accuracy: 0.6603 - val_loss: 0.9284\n",
      "Epoch 11/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.7346 - val_accuracy: 0.6564 - val_loss: 0.9419\n",
      "Epoch 12/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.7140 - val_accuracy: 0.6570 - val_loss: 0.9507\n",
      "Epoch 13/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7432 - loss: 0.6832 - val_accuracy: 0.6470 - val_loss: 0.9773\n",
      "Epoch 14/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7453 - loss: 0.6837 - val_accuracy: 0.6499 - val_loss: 0.9600\n",
      "Epoch 15/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7504 - loss: 0.6692 - val_accuracy: 0.6541 - val_loss: 0.9622\n",
      "Epoch 16/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7551 - loss: 0.6467 - val_accuracy: 0.6555 - val_loss: 0.9714\n",
      "Epoch 17/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7645 - loss: 0.6369 - val_accuracy: 0.6528 - val_loss: 0.9753\n",
      "Epoch 18/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7735 - loss: 0.6129 - val_accuracy: 0.6525 - val_loss: 0.9753\n",
      "Epoch 19/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.6093 - val_accuracy: 0.6564 - val_loss: 0.9845\n",
      "Epoch 20/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7788 - loss: 0.5997 - val_accuracy: 0.6534 - val_loss: 0.9937\n",
      "Epoch 21/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7800 - loss: 0.5926 - val_accuracy: 0.6502 - val_loss: 1.0048\n",
      "Epoch 22/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7854 - loss: 0.5781 - val_accuracy: 0.6584 - val_loss: 0.9846\n",
      "Epoch 23/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7880 - loss: 0.5738 - val_accuracy: 0.6585 - val_loss: 1.0088\n",
      "Epoch 24/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7935 - loss: 0.5607 - val_accuracy: 0.6511 - val_loss: 1.0125\n",
      "Epoch 25/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.5564 - val_accuracy: 0.6527 - val_loss: 1.0233\n",
      "Epoch 26/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8022 - loss: 0.5336 - val_accuracy: 0.6534 - val_loss: 1.0154\n",
      "Epoch 27/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8084 - loss: 0.5274 - val_accuracy: 0.6606 - val_loss: 1.0401\n",
      "Epoch 28/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.5269 - val_accuracy: 0.6524 - val_loss: 1.0624\n",
      "Epoch 29/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.5154 - val_accuracy: 0.6524 - val_loss: 1.0403\n",
      "Epoch 30/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.5089 - val_accuracy: 0.6521 - val_loss: 1.0440\n",
      "Epoch 31/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.5070 - val_accuracy: 0.6557 - val_loss: 1.0471\n",
      "Epoch 32/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4955 - val_accuracy: 0.6532 - val_loss: 1.0441\n",
      "Epoch 33/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.4800 - val_accuracy: 0.6530 - val_loss: 1.0694\n",
      "Epoch 34/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.4819 - val_accuracy: 0.6540 - val_loss: 1.0688\n",
      "Epoch 35/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8274 - loss: 0.4767 - val_accuracy: 0.6568 - val_loss: 1.0868\n",
      "Epoch 36/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.4679 - val_accuracy: 0.6548 - val_loss: 1.0937\n",
      "Epoch 37/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.4747 - val_accuracy: 0.6511 - val_loss: 1.0896\n",
      "Epoch 38/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8346 - loss: 0.4593 - val_accuracy: 0.6537 - val_loss: 1.0916\n",
      "Epoch 39/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.4516 - val_accuracy: 0.6542 - val_loss: 1.0851\n",
      "Epoch 40/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.4510 - val_accuracy: 0.6501 - val_loss: 1.1209\n",
      "Epoch 41/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8445 - loss: 0.4273 - val_accuracy: 0.6493 - val_loss: 1.0929\n",
      "Epoch 42/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8413 - loss: 0.4307 - val_accuracy: 0.6508 - val_loss: 1.1137\n",
      "Epoch 43/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8375 - loss: 0.4316 - val_accuracy: 0.6525 - val_loss: 1.1045\n",
      "Epoch 44/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4268 - val_accuracy: 0.6520 - val_loss: 1.1032\n",
      "Epoch 45/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.4205 - val_accuracy: 0.6570 - val_loss: 1.1056\n",
      "Epoch 46/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8520 - loss: 0.4166 - val_accuracy: 0.6544 - val_loss: 1.1154\n",
      "Epoch 47/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8511 - loss: 0.4033 - val_accuracy: 0.6526 - val_loss: 1.1230\n",
      "Epoch 48/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.4112 - val_accuracy: 0.6563 - val_loss: 1.1319\n",
      "Epoch 49/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.4109 - val_accuracy: 0.6541 - val_loss: 1.1325\n",
      "Epoch 50/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.4091 - val_accuracy: 0.6525 - val_loss: 1.1292\n",
      "Epoch 51/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8518 - loss: 0.4144 - val_accuracy: 0.6532 - val_loss: 1.1400\n",
      "Epoch 52/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8606 - loss: 0.3881 - val_accuracy: 0.6542 - val_loss: 1.1480\n",
      "Epoch 53/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8618 - loss: 0.3889 - val_accuracy: 0.6513 - val_loss: 1.1478\n",
      "Epoch 54/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8540 - loss: 0.3987 - val_accuracy: 0.6568 - val_loss: 1.1333\n",
      "Epoch 55/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.3798 - val_accuracy: 0.6498 - val_loss: 1.1452\n",
      "Epoch 56/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3849 - val_accuracy: 0.6475 - val_loss: 1.1439\n",
      "Epoch 57/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.3806 - val_accuracy: 0.6457 - val_loss: 1.1760\n",
      "Epoch 58/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8589 - loss: 0.3877 - val_accuracy: 0.6483 - val_loss: 1.1516\n",
      "Epoch 59/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3781 - val_accuracy: 0.6508 - val_loss: 1.1575\n",
      "Epoch 60/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.3596 - val_accuracy: 0.6502 - val_loss: 1.1653\n",
      "Epoch 61/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8650 - loss: 0.3708 - val_accuracy: 0.6534 - val_loss: 1.1782\n",
      "Epoch 62/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.3525 - val_accuracy: 0.6481 - val_loss: 1.1724\n",
      "Epoch 63/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8694 - loss: 0.3649 - val_accuracy: 0.6481 - val_loss: 1.1995\n",
      "Epoch 64/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8741 - loss: 0.3574 - val_accuracy: 0.6481 - val_loss: 1.1885\n",
      "Epoch 65/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.3563 - val_accuracy: 0.6511 - val_loss: 1.1892\n",
      "Epoch 66/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.3533 - val_accuracy: 0.6527 - val_loss: 1.1992\n",
      "Epoch 67/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.3230 - val_accuracy: 0.6464 - val_loss: 1.2260\n",
      "Epoch 68/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8778 - loss: 0.3398 - val_accuracy: 0.6510 - val_loss: 1.1927\n",
      "Epoch 69/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.3310 - val_accuracy: 0.6469 - val_loss: 1.2268\n",
      "Epoch 70/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.3302 - val_accuracy: 0.6452 - val_loss: 1.2139\n",
      "Epoch 71/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8764 - loss: 0.3432 - val_accuracy: 0.6461 - val_loss: 1.2307\n",
      "Epoch 72/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8824 - loss: 0.3223 - val_accuracy: 0.6487 - val_loss: 1.2128\n",
      "Epoch 73/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8770 - loss: 0.3442 - val_accuracy: 0.6473 - val_loss: 1.1914\n",
      "Epoch 74/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8814 - loss: 0.3193 - val_accuracy: 0.6455 - val_loss: 1.2375\n",
      "Epoch 75/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8781 - loss: 0.3331 - val_accuracy: 0.6459 - val_loss: 1.2266\n",
      "Epoch 76/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.3138 - val_accuracy: 0.6460 - val_loss: 1.2226\n",
      "Epoch 77/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.3315 - val_accuracy: 0.6474 - val_loss: 1.2027\n",
      "Epoch 78/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8839 - loss: 0.3150 - val_accuracy: 0.6486 - val_loss: 1.2179\n",
      "Epoch 79/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.3120 - val_accuracy: 0.6491 - val_loss: 1.2319\n",
      "Epoch 80/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.3222 - val_accuracy: 0.6423 - val_loss: 1.2258\n",
      "Epoch 81/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.3016 - val_accuracy: 0.6453 - val_loss: 1.2557\n",
      "Epoch 82/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8820 - loss: 0.3225 - val_accuracy: 0.6483 - val_loss: 1.2201\n",
      "Epoch 83/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.3029 - val_accuracy: 0.6513 - val_loss: 1.2297\n",
      "Epoch 84/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.2963 - val_accuracy: 0.6509 - val_loss: 1.2480\n",
      "Epoch 85/100\n",
      "\u001b[1m241/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.3034"
     ]
    }
   ],
   "source": [
    "# train_and_evaluate_model(\n",
    "#     build_custom_model, X_train, y_train_encoded, X_val_normalized, y_val_encoded, label_encoder\n",
    "# )\n",
    "train_and_evaluate_model(\n",
    "    build_custom_model_batch,\n",
    "    X_train_normalized,\n",
    "    y_train_encoded,\n",
    "    X_val_normalized,\n",
    "    y_val_encoded,\n",
    "    label_encoder,\n",
    ")\n",
    "# train_and_evaluate_model(\n",
    "#     build_cnn_model, X_train, y_train_encoded, X_val_normalized, y_val_encoded, label_encoder\n",
    "# )\n",
    "# train_and_evaluate_model(\n",
    "#     build_bidirectional_lstm,\n",
    "#     X_train,\n",
    "#     y_train_encoded,\n",
    "#     X_val_normalized,\n",
    "#     y_val_encoded,\n",
    "#     label_encoder,\n",
    "# )\n",
    "# train_and_evaluate_model(\n",
    "#     build_lstm_with_attention,\n",
    "#     X_train,\n",
    "#     y_train_encoded,\n",
    "#     X_val_normalized,\n",
    "#     y_val_encoded,\n",
    "#     label_encoder,\n",
    "# )\n",
    "# train_and_evaluate_model(\n",
    "#     build_ensemble_model,\n",
    "#     X_train,\n",
    "#     y_train_encoded,\n",
    "#     X_val_normalized,\n",
    "#     y_val_encoded,\n",
    "#     label_encoder,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom model 1\n",
    "def build_custom_model_1(input_shape, num_classes):\n",
    "    input_layer = Input(input_shape)\n",
    "    x = Dense(128, activation=\"relu\")(input_layer)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    output_layer = Dense(num_classes, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define custom model 2\n",
    "def build_custom_model_2(input_shape, num_classes):\n",
    "    input_layer = Input(input_shape)\n",
    "    x = Dense(256, activation=\"relu\")(input_layer)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    output_layer = Dense(num_classes, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define custom model 3\n",
    "def build_custom_model_3(input_shape, num_classes):\n",
    "    input_layer = Input(input_shape)\n",
    "    x = Dense(256, activation=\"relu\")(input_layer)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    output_layer = Dense(num_classes, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Load and preprocess the data\n",
    "# Assuming you have already loaded and preprocessed the data as X_train, y_train, X_val, y_val\n",
    "\n",
    "# Build and compile custom model 1\n",
    "model_1 = build_custom_model_1(\n",
    "    input_shape=X_train_normalized.shape[1:], num_classes=len(label_encoder.classes_)\n",
    ")\n",
    "model_1.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Build and compile custom model 2\n",
    "model_2 = build_custom_model_2(\n",
    "    input_shape=X_train_normalized.shape[1:], num_classes=len(label_encoder.classes_)\n",
    ")\n",
    "model_2.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Build and compile custom model 3\n",
    "model_3 = build_custom_model_3(\n",
    "    input_shape=X_train_normalized.shape[1:], num_classes=len(label_encoder.classes_)\n",
    ")\n",
    "model_3.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_ensemble_model(\n",
    "    X_train_normalized, y_train, X_val_normalized, y_val, label_encoder\n",
    "):\n",
    "    # Define build_model function for each custom model\n",
    "    build_model_funcs = [\n",
    "        build_custom_model_1,\n",
    "        build_custom_model_2,\n",
    "        build_custom_model_3,\n",
    "    ]\n",
    "\n",
    "    # Train and evaluate each custom model\n",
    "    models = []\n",
    "    for build_model_func in build_model_funcs:\n",
    "        model = build_model_func(\n",
    "            input_shape=X_train_normalized.shape[1:],\n",
    "            num_classes=len(label_encoder.classes_),\n",
    "        )\n",
    "        train_and_evaluate_model(\n",
    "            build_model_func,\n",
    "            X_train_normalized,\n",
    "            y_train,\n",
    "            X_val_normalized,\n",
    "            y_val,\n",
    "            label_encoder,\n",
    "        )\n",
    "        models.append(model)\n",
    "\n",
    "    # Ensemble predictions\n",
    "    preds_ensemble = np.mean(\n",
    "        [model.predict(X_val_normalized) for model in models], axis=0\n",
    "    )\n",
    "    y_val_pred = np.argmax(preds_ensemble, axis=-1)\n",
    "\n",
    "    # Compute class-wise accuracy\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    class_wise_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1_scores = []\n",
    "    for genre, acc in zip(label_encoder.classes_, class_wise_accuracy):\n",
    "        precision = (\n",
    "            conf_matrix[\n",
    "                label_encoder.transform([genre]), label_encoder.transform([genre])\n",
    "            ]\n",
    "            / conf_matrix[:, label_encoder.transform([genre])].sum()\n",
    "        )\n",
    "        recall = (\n",
    "            conf_matrix[\n",
    "                label_encoder.transform([genre]), label_encoder.transform([genre])\n",
    "            ]\n",
    "            / conf_matrix[label_encoder.transform([genre]), :].sum()\n",
    "        )\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        f1_scores.append(f1_score)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"\\nEnsemble Model Evaluation:\")\n",
    "    print(\"\\nClass-wise Accuracy:\")\n",
    "    for genre, acc in zip(label_encoder.classes_, class_wise_accuracy):\n",
    "        print(f\"{genre}: {acc}\")\n",
    "    print(\"\\nF1 Scores:\")\n",
    "    for genre, f1 in zip(label_encoder.classes_, f1_scores):\n",
    "        print(f\"{genre}: {f1}\")\n",
    "\n",
    "\n",
    "# Train and evaluate ensemble model\n",
    "train_and_evaluate_ensemble_model(\n",
    "    X_train_normalized, y_train_encoded, X_val_normalized, y_val_encoded, label_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenization\n",
    "# tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "# tokenizer.fit_on_texts(X_train_normalized)\n",
    "\n",
    "# X_train_tokenized = tokenizer.texts_to_sequences(X_train_normalized)\n",
    "# X_val_tokenized = tokenizer.texts_to_sequences(X_val_normalized)\n",
    "\n",
    "# vocab_size = len(tokenizer.word_index) + 1\n",
    "# max_seq_length = max(len(seq) for seq in X_train_tokenized)\n",
    "\n",
    "# # Padding sequences\n",
    "# X_train_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#     X_train_tokenized, maxlen=max_seq_length, padding=\"post\"\n",
    "# )\n",
    "# X_val_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#     X_val_tokenized, maxlen=max_seq_length, padding=\"post\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Positional encoding\n",
    "# def positional_encoding(seq_length, d_model):\n",
    "#     pos = np.arange(seq_length)[:, np.newaxis]\n",
    "#     i = np.arange(d_model)[np.newaxis, :]\n",
    "#     angles = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "#     pos_encoding = pos * angles\n",
    "\n",
    "#     pos_encoding[:, 0::2] = np.sin(pos_encoding[:, 0::2])\n",
    "#     pos_encoding[:, 1::2] = np.cos(pos_encoding[:, 1::2])\n",
    "#     pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "\n",
    "#     return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# # Transformer Encoder Layer\n",
    "# class TransformerEncoderLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "#         super(TransformerEncoderLayer, self).__init__()\n",
    "\n",
    "#         self.mha = tf.keras.layers.MultiHeadAttention(\n",
    "#             num_heads=num_heads, key_dim=d_model\n",
    "#         )\n",
    "#         self.ffn = tf.keras.Sequential(\n",
    "#             [\n",
    "#                 tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
    "#                 tf.keras.layers.Dense(d_model),\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "#         self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "#         self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "#         self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "#     def call(self, inputs, training):\n",
    "#         attn_output = self.mha(inputs, inputs, inputs)\n",
    "#         attn_output = self.dropout1(attn_output, training=training)\n",
    "#         out1 = self.layernorm1(inputs + attn_output)\n",
    "\n",
    "#         ffn_output = self.ffn(out1)\n",
    "#         ffn_output = self.dropout2(ffn_output, training=training)\n",
    "#         out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "#         return out2\n",
    "\n",
    "\n",
    "# # Transformer Model\n",
    "# class TransformerModel(tf.keras.Model):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         num_layers,\n",
    "#         d_model,\n",
    "#         num_heads,\n",
    "#         dff,\n",
    "#         vocab_size,\n",
    "#         num_classes,\n",
    "#         max_seq_length,\n",
    "#         rate=0.1,\n",
    "#     ):\n",
    "#         super(TransformerModel, self).__init__()\n",
    "#         self.d_model = d_model\n",
    "#         self.num_layers = num_layers\n",
    "#         self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "#         self.pos_encoding = positional_encoding(max_seq_length, d_model)\n",
    "#         self.enc_layers = [\n",
    "#             TransformerEncoderLayer(d_model, num_heads, dff, rate)\n",
    "#             for _ in range(num_layers)\n",
    "#         ]\n",
    "#         self.dropout = tf.keras.layers.Dropout(rate)\n",
    "#         self.final_layer = tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "#     def call(self, inputs, training):\n",
    "#         seq_len = tf.shape(inputs)[1]\n",
    "#         x = self.embedding(inputs)\n",
    "#         x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "#         x += self.pos_encoding[:, :seq_len, :]\n",
    "#         x = self.dropout(x, training=training)\n",
    "\n",
    "#         for i in range(self.num_layers):\n",
    "#             x = self.enc_layers[i](x, training)\n",
    "\n",
    "#         x = tf.reduce_mean(x, axis=1)  # Global average pooling\n",
    "#         return self.final_layer(x)\n",
    "\n",
    "\n",
    "# # Instantiate the Transformer model\n",
    "# num_layers = 4\n",
    "# d_model = 128\n",
    "# num_heads = 8\n",
    "# dff = 512\n",
    "\n",
    "# transformer_model = TransformerModel(\n",
    "#     num_layers,\n",
    "#     d_model,\n",
    "#     num_heads,\n",
    "#     dff,\n",
    "#     vocab_size,\n",
    "#     len(label_encoder.classes_),\n",
    "#     max_seq_length,\n",
    "# )\n",
    "\n",
    "# # Compile the model\n",
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "# transformer_model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "# # # Train the model\n",
    "# # history = transformer_model.fit(\n",
    "# #     X_train_padded,\n",
    "# #     y_train_encoded,\n",
    "# #     epochs=10,\n",
    "# #     validation_data=(X_val_padded, y_val_encoded),\n",
    "# #     class_weight=class_weights,\n",
    "# # )\n",
    "# # Train the model\n",
    "# history = transformer_model.fit(\n",
    "#     X_train_padded,\n",
    "#     y_train_encoded,\n",
    "#     epochs=10,\n",
    "#     validation_data=(X_val_padded, y_val_encoded),\n",
    "#     # class_weight=class_weights,\n",
    "# )\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = transformer_model.evaluate(X_val_padded, y_val_encoded)\n",
    "# print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = transformer_model.evaluate(X_val_padded, y_val_encoded)\n",
    "# print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
